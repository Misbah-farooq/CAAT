{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a58b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from torchaudio.pipelines import HUBERT_BASE\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from pytorch_metric_learning.losses import TripletMarginLoss\n",
    "from pytorch_metric_learning.miners import TripletMarginMiner\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load dataset\n",
    "full_data = pd.read_csv('/home/misbahfarooq/Desktop/111-cross-iemocap/iemocap/IEMOCAP_full_release/iemocap_4class-s+d.csv')\n",
    "\n",
    "# Map emotions to integers\n",
    "emotion_mapping = {'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n",
    "full_data['Emotion_label'] = full_data['Emotion'].map(emotion_mapping)\n",
    "\n",
    "# Train-test split\n",
    "train_val_data, test_data = train_test_split(\n",
    "    full_data, test_size=0.2, stratify=full_data['Emotion_label'], random_state=42\n",
    ")\n",
    "\n",
    "X_full = train_val_data['wav_path'].tolist()\n",
    "y_full = train_val_data['Emotion_label'].values\n",
    "X_test = test_data['wav_path'].tolist()\n",
    "y_test = test_data['Emotion_label'].values\n",
    "\n",
    "# Dataset class\n",
    "class HuBERTEmotionDataset(Dataset):\n",
    "    def __init__(self, wav_paths, labels, target_length=48000):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = torch.tensor(labels)\n",
    "        self.resampler = torchaudio.transforms.Resample(orig_freq=48000, new_freq=48000)\n",
    "        self.target_length = target_length  # target length for padding/truncation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sr = torchaudio.load(self.wav_paths[idx])\n",
    "        if sr != 48000:\n",
    "            waveform = self.resampler(waveform)\n",
    "\n",
    "        # Padding or truncating to target_length\n",
    "        if waveform.size(1) < self.target_length:\n",
    "            padding = self.target_length - waveform.size(1)\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "        elif waveform.size(1) > self.target_length:\n",
    "            waveform = waveform[:, :self.target_length]\n",
    "\n",
    "        return waveform.squeeze(0), self.labels[idx]\n",
    "\n",
    "\n",
    "# Model definition\n",
    "class HuBERTClassifierWithEmbeddings(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hubert = HUBERT_BASE.get_model()\n",
    "        self.project = nn.Linear(768, 768)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(768, 4)\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "        with torch.no_grad():\n",
    "            features, _ = self.hubert(waveforms)\n",
    "            \n",
    "        embeddings = features.mean(dim=1)\n",
    "        embeddings = self.project(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits, embeddings\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader, return_preds=False):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for waveforms, labels in loader:\n",
    "            waveforms = waveforms.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits, _ = model(waveforms)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    if return_preds:\n",
    "        return acc, prec, rec, f1, y_true, y_pred\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "# Confusion matrix plot\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Training function\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, num_epochs=10, batch_size=64):\n",
    "    train_loader = DataLoader(HuBERTEmotionDataset(X_train, y_train), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(HuBERTEmotionDataset(X_val, y_val), batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "    model = HuBERTClassifierWithEmbeddings().to(device)\n",
    "    clf_criterion = nn.CrossEntropyLoss()\n",
    "    distance = CosineSimilarity()\n",
    "    triplet_loss_fn = TripletMarginLoss(margin=0.5, distance=distance)\n",
    "    miner = TripletMarginMiner(margin=0.5, distance=distance, type_of_triplets=\"hard\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    triplet_loss_weight = 0.5\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_clf_loss, total_triplet_loss = 0.0, 0.0\n",
    "        for waveforms, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            waveforms = waveforms.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits, embeddings = model(waveforms)\n",
    "            embeddings = nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "            clf_loss = clf_criterion(logits, labels)\n",
    "            hard_triplets = miner(embeddings, labels)\n",
    "            if len(hard_triplets[0]) > 0:\n",
    "                triplet_loss = triplet_loss_fn(embeddings, labels, hard_triplets)\n",
    "            else:\n",
    "                triplet_loss = torch.tensor(0.0).to(device)\n",
    "\n",
    "            total_loss = clf_loss + triplet_loss_weight * triplet_loss\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_clf_loss += clf_loss.item()\n",
    "            total_triplet_loss += triplet_loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        _, _, _, val_f1 = evaluate(model, val_loader)\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Clf Loss: {total_clf_loss/len(train_loader):.4f}, \"\n",
    "              f\"Triplet Loss: {total_triplet_loss/len(train_loader):.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "\n",
    "# 5-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "fold_results = []\n",
    "best_model_state_dict = None\n",
    "best_f1_score = 0\n",
    "best_fold = -1\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full, y_full)):\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "    X_tr = [X_full[i] for i in train_idx]\n",
    "    y_tr = y_full[train_idx]\n",
    "    X_va = [X_full[i] for i in val_idx]\n",
    "    y_va = y_full[val_idx]\n",
    "\n",
    "    model = train_and_evaluate(X_tr, y_tr, X_va, y_va)\n",
    "\n",
    "    test_loader = DataLoader(HuBERTEmotionDataset(X_test, y_test), batch_size=64)\n",
    "    test_acc, test_prec, test_rec, test_f1 = evaluate(model, test_loader)\n",
    "\n",
    "    print(f\"\\u2192 Fold {fold+1} Test Accuracy: {test_acc*100:.2f}%, F1: {test_f1:.4f}, \"\n",
    "          f\"Precision: {test_prec:.4f}, Recall: {test_rec:.4f}\")\n",
    "    fold_results.append((test_acc, test_prec, test_rec, test_f1))\n",
    "\n",
    "    if test_f1 > best_f1_score:\n",
    "        best_f1_score = test_f1\n",
    "        best_model_state_dict = model.state_dict()\n",
    "        best_fold = fold\n",
    "\n",
    "# Summary\n",
    "fold_results = np.array(fold_results)\n",
    "print(\"\\n===== Final Cross-Validated Test Results =====\")\n",
    "print(f\"Avg Accuracy: {fold_results[:,0].mean()*100:.2f}%\")\n",
    "print(f\"Avg Precision: {fold_results[:,1].mean():.4f}\")\n",
    "print(f\"Avg Recall: {fold_results[:,2].mean():.4f}\")\n",
    "print(f\"Avg F1 Score: {fold_results[:,3].mean():.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "print(f\"\\nBest Model Found at Fold {best_fold+1} with F1 Score: {best_f1_score:.4f}\")\n",
    "final_model = HuBERTClassifierWithEmbeddings().to(device)\n",
    "final_model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "test_loader = DataLoader(HuBERTEmotionDataset(X_test, y_test), batch_size=64,num_workers=4, pin_memory=True)\n",
    "test_acc, test_prec, test_rec, test_f1, y_true, y_pred = evaluate(final_model, test_loader, return_preds=True)\n",
    "\n",
    "print(f\"\\n===== Best Fold Final Evaluation on Test Set =====\")\n",
    "print(f\"Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"Precision: {test_prec:.4f}\")\n",
    "print(f\"Recall: {test_rec:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, labels=list(emotion_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100  # Convert to percentage\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix-Audio Modality)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(y_true, y_pred, labels=list(emotion_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca778bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def extract_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for waveforms, labels in tqdm(loader, desc=\"Extracting Embeddings\"):\n",
    "            waveforms = waveforms.to(device)\n",
    "            labels = labels.to(device)\n",
    "            _, embeddings = model(waveforms)\n",
    "            embeddings = nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_embeddings, all_labels\n",
    "\n",
    "\n",
    "# Extract embeddings from the test set\n",
    "test_embeddings, test_labels = extract_embeddings(model, test_loader)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=1000, random_state=42)\n",
    "tsne_results = tsne.fit_transform(test_embeddings)\n",
    "\n",
    "# Plot t-SNE\n",
    "plt.figure(figsize=(8, 6))\n",
    "palette = sns.color_palette(\"bright\", len(emotion_mapping))\n",
    "for i, label in enumerate(emotion_mapping.keys()):\n",
    "    idxs = test_labels == emotion_mapping[label]\n",
    "    plt.scatter(tsne_results[idxs, 0], tsne_results[idxs, 1], label=label, alpha=0.7, s=40, color=palette[i])\n",
    "plt.legend()\n",
    "plt.title(\"t-SNE-Audio-Cross-entropy loss \")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for waveforms, labels in tqdm(loader, desc=\"Extracting Embeddings\"):\n",
    "            waveforms = waveforms.to(device)\n",
    "            labels = labels.to(device)\n",
    "            _, embeddings = model(waveforms)\n",
    "            embeddings = nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_embeddings, all_labels\n",
    "\n",
    "\n",
    "# Extract embeddings from the test set\n",
    "test_embeddings, test_labels = extract_embeddings(model, test_loader)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=1000, random_state=42)\n",
    "tsne_results = tsne.fit_transform(test_embeddings)\n",
    "\n",
    "# Plot t-SNE\n",
    "plt.figure(figsize=(8, 6))\n",
    "palette = sns.color_palette(\"bright\", len(emotion_mapping))\n",
    "for i, label in enumerate(emotion_mapping.keys()):\n",
    "    idxs = test_labels == emotion_mapping[label]\n",
    "    plt.scatter(tsne_results[idxs, 0], tsne_results[idxs, 1], label=label, alpha=0.7, s=40, color=palette[i])\n",
    "\n",
    "# Set labels and title with increased font size\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"t-SNE-Audio-Cross-entropy Loss\", fontsize=16)\n",
    "plt.xlabel(\"Dimension 1\", fontsize=14)\n",
    "plt.ylabel(\"Dimension 2\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
